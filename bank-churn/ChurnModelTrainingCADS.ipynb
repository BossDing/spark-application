{"nbformat_minor": 1, "cells": [{"source": "## Model training of the churn data", "cell_type": "markdown", "metadata": {}}, {"source": "### Import the required libraries", "cell_type": "markdown", "metadata": {}}, {"source": "//import libraries\nimport org.apache.spark.{SparkConf, SparkContext, SparkFiles}\nimport org.apache.spark.sql.{SQLContext, SparkSession, Row}\nimport org.apache.spark.SparkFiles\n\nimport org.apache.spark.ml.feature.{StringIndexer, IndexToString, VectorIndexer, VectorAssembler}\nimport org.apache.spark.ml.regression.LinearRegression\nimport org.apache.spark.ml.classification.{LogisticRegression, DecisionTreeClassifier}\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\nimport org.apache.spark.ml.{Pipeline, PipelineStage}\nimport org.apache.spark.ml.ibm.transformers.RenameColumn\n\nimport com.ibm.analytics.ngp.ingest.Sampling\nimport com.ibm.analytics.ngp.pipeline._\nimport com.ibm.analytics.ngp.util._\nimport com.ibm.analytics.ngp.pipeline.evaluate.{Evaluator,MLProblemType}\n\nimport com.ibm.analytics.{Learner, Target}\nimport com.ibm.analytics.cads.CADSEstimator", "cell_type": "code", "execution_count": 1, "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"source": "### Load the data from DB2 for z/OS into dataframe and split for training, testing and evaluating", "cell_type": "markdown", "metadata": {}}, {"source": "import org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.functions._ \n\n//Load data from DB2 for z/OS using JDBC driver\nval churnDataRaw = spark.read.format(\"jdbc\").\n                        options(Map(\"driver\" -> \"com.ibm.db2.jcc.DB2Driver\",\n                         \"url\" -> \"jdbc:db2://9.125.72.72:430/LOCDB11\", \n                         \"user\" -> \"tuser01\",\"password\" -> \"c4deshop\", \n                         \"dbtable\" -> \"SA.CUST_SUM\")).load()\n\nval toDouble = udf {x: Int => x.toDouble}\n\nval churnData = churnDataRaw.select(\"AGE\", \"ACTIVITY\", \"EDUCATION\", \"SEX\", \"STATE\", \"NEGTWEETS\", \"INCOME\", \"CHURN_LABEL\")\nchurnData.show(5)", "cell_type": "code", "execution_count": 2, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+--------+---------+---+-----+---------+-----------+-----------+\n|AGE|ACTIVITY|EDUCATION|SEX|STATE|NEGTWEETS|     INCOME|CHURN_LABEL|\n+---+--------+---------+---+-----+---------+-----------+-----------+\n| 84|       5|        2|  F|   TX|        3|3852862.000|      false|\n| 44|       1|        2|  F|   CA|        2|3849843.000|      false|\n| 23|       1|        2|  F|   CA|        5|3217364.000|       true|\n| 24|       4|        2|  F|   WA|        2|2438218.000|       true|\n| 67|       3|        5|  F|   CT|        3|2428245.000|      false|\n+---+--------+---------+---+-----+---------+-----------+-----------+\nonly showing top 5 rows\n\n"}], "metadata": {"trusted": true}}, {"source": "val train = 70\nval test = 15\nval validate = 15\n\n//Split the data into training data set, testing data set, and validation data set\n\nval splits = Sampling.trainingSplit(churnData, train, test, validate)\n\nval trainingDF = splits._1\nval testDF = splits._2\nval validationDF = splits._3\n\nprintln(\"Training data set\")\ntrainingDF.show(5)\n\nprintln(\"Testing data set\")\ntestDF.show(5)\n\nprintln(\"Validation data set\")\nvalidationDF.show(5)", "cell_type": "code", "execution_count": 3, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Training data set\n+---+--------+---------+---+-----+---------+---------+-----------+\n|AGE|ACTIVITY|EDUCATION|SEX|STATE|NEGTWEETS|   INCOME|CHURN_LABEL|\n+---+--------+---------+---+-----+---------+---------+-----------+\n| 20|       0|        1|  F|   ID|       13|17877.000|       true|\n| 20|       0|        1|  F|   WA|       15|15497.000|       true|\n| 20|       1|        1|  F|   PA|        6|19556.000|       true|\n| 20|       1|        1|  F|   WV|        3|20687.000|      false|\n| 20|       1|        1|  M|   ID|        6|18453.000|       true|\n+---+--------+---------+---+-----+---------+---------+-----------+\nonly showing top 5 rows\n\nTesting data set\n+---+--------+---------+---+-----+---------+---------+-----------+\n|AGE|ACTIVITY|EDUCATION|SEX|STATE|NEGTWEETS|   INCOME|CHURN_LABEL|\n+---+--------+---------+---+-----+---------+---------+-----------+\n| 20|       0|        1|  F|   CA|        7|17088.000|       true|\n| 20|       1|        1|  F|   TN|        3|13480.000|      false|\n| 20|       2|        1|  F|   KY|        3|14811.000|      false|\n| 20|       3|        2|  M|   AL|        3|91918.000|      false|\n| 20|       4|        1|  M|   IL|        4|21811.000|      false|\n+---+--------+---------+---+-----+---------+---------+-----------+\nonly showing top 5 rows\n\nValidation data set\n+---+--------+---------+---+-----+---------+---------+-----------+\n|AGE|ACTIVITY|EDUCATION|SEX|STATE|NEGTWEETS|   INCOME|CHURN_LABEL|\n+---+--------+---------+---+-----+---------+---------+-----------+\n| 20|       0|        1|  M|   CA|        7|16982.000|       true|\n| 20|       1|        1|  F|   ID|        7|19761.000|       true|\n| 20|       1|        1|  M|   ND|       13|16552.000|       true|\n| 20|       1|        1|  M|   PA|        1|22424.000|      false|\n| 20|       1|        2|  M|   MD|       11|22139.000|       true|\n+---+--------+---------+---+-----+---------+---------+-----------+\nonly showing top 5 rows\n\n"}], "metadata": {"trusted": true}}, {"source": "### Use CADS(Cognitive Assistant of Data Science) to train & recommend the best model automatically from DT and LR", "cell_type": "markdown", "metadata": {}}, {"source": "//Feature definition\n\nval genderIndexer = new StringIndexer().setInputCol(\"SEX\").setOutputCol(\"gender_code\")\nval stateIndexer = new StringIndexer().setInputCol(\"STATE\").setOutputCol(\"state_code\")\nval labelIndexer = new StringIndexer().setInputCol(\"CHURN_LABEL\").setOutputCol(\"label\")\n\nval featuresAssembler = new VectorAssembler().setInputCols(Array(\"AGE\", \n                                                         \"ACTIVITY\", \n                                                         \"EDUCATION\", \n                                                         \"NEGTWEETS\" ,\n                                                         \"INCOME\",\n                                                         \"gender_code\",\n                                                         \"state_code\")).setOutputCol(\"features\")", "cell_type": "code", "execution_count": 4, "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"source": "//Select model automatically in candidate algorithm - Logistic Regression, SVM or Decision Tree?\nval lr = new LogisticRegression().setRegParam(0.01).setLabelCol(\"label\").setFeaturesCol(\"features\")\nval decisionTree = new DecisionTreeClassifier().setMaxBins(50).setLabelCol(\"label\").setFeaturesCol(\"features\")", "cell_type": "code", "execution_count": 5, "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"source": "//Cognitive Assistant for Data Scientists - predict model performance based on sampled data\nval learners = List(Learner(\"DT\", decisionTree), Learner(\"LR\", lr))\nval cads = CADSEstimator().setEvaluator(new BinaryClassificationEvaluator().\n                           setMetricName(\"areaUnderROC\")).\n                           setLearners(learners).\n                           setKeepBestNLearnersParam(3).\n                           setTarget(Target(\"rawPrediction\", \"label\")).\n                           setNumSampleFoldsParam(2)\nval pipeline = new IBMSparkPipeline().setStages(Array(labelIndexer, genderIndexer, stateIndexer, featuresAssembler, cads))\nval model = pipeline.fit(trainingDF)", "cell_type": "code", "execution_count": 6, "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"source": "### Evaluate the trained model and draw the ROC curve", "cell_type": "markdown", "metadata": {}}, {"source": "import com.ibm.analytics.ngp.pipeline.evaluate._\nimport com.ibm.analytics.ngp.pipeline.evaluate.JsonMetricsModel._\nimport spray.json._\n\nval metrics = Evaluator.evaluateModel(MLProblemType.BinaryClassifier,model,testDF)\n\nprintln(s\"Binary Metric: ${metrics.asInstanceOf[BinaryClassificationMetricsModel].toJson}\")\n\n//Saving the model on file system if needed:\n//model.saveToLocalPath(\"bfusr21/churnModel\", \"/home/bfusr21/model.tar.gz\") \n\nConnections.setEnvironment(\"dev\")\nConnections.setMetaServiceHost(\"http://9.30.166.110:12501\")\nmodel.save(\"steve/ChurnCADSModel\")\n\nprintln(\"Model saved successfully, you can view and deploy in the model management dashboard\")", "cell_type": "code", "execution_count": 1, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Binary Metric: {\"recallByThreshold\":[{\"threshold\":1.0,\"metric\":0.9018691588785047},{\"threshold\":0.0,\"metric\":1.0}],\"precisionByThreshold\":[{\"threshold\":1.0,\"metric\":0.9897435897435898},{\"threshold\":0.0,\"metric\":0.23336968375136313}],\"areaUnderPR\":0.9572567559904366,\"fMeasureByThreshold\":[{\"threshold\":1.0,\"metric\":0.9437652811735943},{\"threshold\":0.0,\"metric\":0.37842617152961977}],\"roc\":[{\"threshold\":0.0,\"metric\":0.0},{\"threshold\":0.002844950213371266,\"metric\":0.9018691588785047},{\"threshold\":1.0,\"metric\":1.0},{\"threshold\":1.0,\"metric\":1.0}],\"areaUnderROC\":0.9495121043325667}\nModel saved successfully, you can view and deploy in the model management dashboard\n"}], "metadata": {"trusted": true}}, {"source": "val rocCurve = metrics.asInstanceOf[BinaryClassificationMetricsModel].roc.map{ case ThresholdMetricModel(x, y) => (x,y)}", "cell_type": "code", "execution_count": 8, "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"source": "val rocDF = spark.createDataFrame(rocCurve).\n                    withColumnRenamed(\"_1\", \"FPR\").\n                    withColumnRenamed(\"_2\", \"TPR\")\nrocDF.show(3)", "cell_type": "code", "execution_count": 9, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------------------+------------------+\n|                 FPR|               TPR|\n+--------------------+------------------+\n|                 0.0|               0.0|\n|0.002844950213371266|0.9018691588785047|\n|                 1.0|               1.0|\n+--------------------+------------------+\nonly showing top 3 rows\n\n"}], "metadata": {"trusted": true}}, {"source": "%AddJar -magic https://brunelvis.org/jar/spark-kernel-brunel-all-2.3.jar -f", "cell_type": "code", "execution_count": 10, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting download from https://brunelvis.org/jar/spark-kernel-brunel-all-2.3.jar\nFinished download of spark-kernel-brunel-all-2.3.jar\n"}], "metadata": {"trusted": true}}, {"source": "%%brunel data('rocDF') x(FPR) y(TPR) line tooltip(#all) axes(x:'False Positive Rate':grid, y:'True Positive Rate':grid) title('ROC') ", "cell_type": "code", "execution_count": 11, "outputs": [{"output_type": "execute_result", "data": {"text/html": "\n         <link rel=\"stylesheet\" type=\"text/css\" href=\"https://brunelvis.org/js/brunel.2.3.css\" charset=\"utf-8\">\n         <link rel=\"stylesheet\" type=\"text/css\" href=\"https://brunelvis.org/js/sumoselect.css\" charset=\"utf-8\">\n         <style>  </style>\n         <div id=\"controlsId75d0e390-a155-49bb-b066-f26edb8cdfbf\" class=\"brunel\"/>\n<svg id=\"visidb4eec110-2a26-4710-9fa8-f678a2a1b52c\" width=\"500\" height=\"400\"></svg>\n\n<script>\nrequire.config({\n            waitSeconds: 60,\n            paths: {\n                'd3': '//cdnjs.cloudflare.com/ajax/libs/d3/4.2.1/d3.min',\n                'topojson' : '//cdnjs.cloudflare.com/ajax/libs/topojson/1.6.20/topojson.min',\n                'brunel' : 'https://brunelvis.org/js/brunel.2.3.min',\n                'brunelControls' : 'https://brunelvis.org/js/brunel.controls.2.3.min'\n            },\n\n            shim: {\n               'brunel' : {\n                    exports: 'BrunelD3',\n                    deps: ['d3', 'topojson'],\n                    init: function() {\n                       return {\n                         BrunelD3 : BrunelD3,\n                         BrunelData : BrunelData\n                      }\n                    }\n                },\n               'brunelControls' : {\n                    exports: 'BrunelEventHandlers',\n                    init: function() {\n                       return {\n                         BrunelEventHandlers: BrunelEventHandlers,\n                         BrunelJQueryControlFactory: BrunelJQueryControlFactory\n                      }\n                    }\n                }\n\n            }\n\n        });\n\n        require([\"d3\"], function(d3) {\n        require([\"brunel\", \"brunelControls\"], function(brunel, brunelControls) {\n\n            function  BrunelVis(visId) {\n  \"use strict\"; // Strict Mode\n  var datasets = [],                                         // Array of datasets for the original data\n      pre = function(d, i) { return d },                     // Default pre-process does nothing\n      post = function(d, i) { return d },                    // Default post-process does nothing\n      transitionTime = 200,                                  // Transition time for animations\n      charts = [],                                           // The charts in the system\n      hasData = function(d) {return d && (d.row != null || hasData(d.data))}, // Filters to data items\n      vis = d3.select('#' + visId).attr('class', 'brunel'),  // the SVG container\n      isSelected = function(data) { return function(d) {return data.$selection(d)=='\u2713'} }; // returns a filter function identifying selected items\n\n  // Define chart #1 in the visualization //////////////////////////////////////////////////////////\n\n  charts[0] = function(parentNode, filterRows) {\n    var geom = BrunelD3.geometry(parentNode || vis.node(), 0, 0, 1, 1, 27, 43, 37, 13),\n      elements = [];                               // Array of elements in this chart\n\n    // Define groups for the chart parts ///////////////////////////////////////////////////////////\n\n    var chart =  vis.append('g').attr('class', 'chart1')\n      .attr('transform','translate(' + geom.chart_left + ',' + geom.chart_top + ')');\n    var overlay = chart.append('g').attr('class', 'element').attr('class', 'overlay');\n    var zoom = d3.zoom().scaleExtent([1/3,3]);\n    var zoomNode = overlay.append('rect').attr('class', 'overlay')\n      .attr('x', geom.inner_left).attr('y', geom.inner_top)\n      .attr('width', geom.inner_rawWidth).attr('height', geom.inner_rawHeight)\n      .style('cursor', 'move').call(zoom)\n      .node();\n    zoomNode.__zoom = d3.zoomIdentity;\n    chart.append('rect').attr('class', 'background').attr('width', geom.chart_right-geom.chart_left).attr('height', geom.chart_bottom-geom.chart_top);\n    var interior = chart.append('g').attr('class', 'interior zoomNone')\n      .attr('transform','translate(' + geom.inner_left + ',' + geom.inner_top + ')')\n      .attr('clip-path', 'url(#clip_visidb4eec110-2a26-4710-9fa8-f678a2a1b52c_chart1_inner)');\n    interior.append('rect').attr('class', 'inner').attr('width', geom.inner_width).attr('height', geom.inner_height);\n    var gridGroup = interior.append('g').attr('class', 'grid');\n    var axes = chart.append('g').attr('class', 'axis')\n      .attr('transform','translate(' + geom.inner_left + ',' + geom.inner_top + ')');\n    vis.append('clipPath').attr('id', 'clip_visidb4eec110-2a26-4710-9fa8-f678a2a1b52c_chart1_inner').append('rect')\n      .attr('x', 0).attr('y', 0)\n      .attr('width', geom.inner_rawWidth+1).attr('height', geom.inner_rawHeight+1);\n    chart.append('text').attr('class', 'title header').text('ROC').style('text-anchor', 'middle')\n      .attr('x','50%')\n      .attr('y',2).attr('dy','0.8em');\n\n    // Scales //////////////////////////////////////////////////////////////////////////////////////\n\n    var scale_x = d3.scaleLinear().domain([0, 1.0000001])\n      .range([0, geom.inner_width]);\n    var scale_inner = d3.scaleLinear().domain([0,1])\n      .range([-0.5, 0.5]);\n    var scale_y = d3.scaleLinear().domain([0, 1.0000001])\n      .range([geom.inner_height, 0]);\n    var base_scales = [scale_x, scale_y];          // Untransformed original scales\n\n    // Axes ////////////////////////////////////////////////////////////////////////////////////////\n\n    axes.append('g').attr('class', 'x axis')\n      .attr('transform','translate(0,' + geom.inner_rawHeight + ')')\n      .attr('clip-path', 'url(#clip_visidb4eec110-2a26-4710-9fa8-f678a2a1b52c_chart1_haxis)');\n    vis.append('clipPath').attr('id', 'clip_visidb4eec110-2a26-4710-9fa8-f678a2a1b52c_chart1_haxis').append('polyline')\n      .attr('points', '-1,-1000, -1,-1 -5,5, -1000,5, -100,1000, 10000,1000 10000,-1000');\n    axes.select('g.axis.x').append('text').attr('class', 'title').text('False Positive Rate').style('text-anchor', 'middle')\n      .attr('x',geom.inner_rawWidth/2)\n      .attr('y', geom.inner_bottom - 2.0).attr('dy','-0.27em');\n    axes.append('g').attr('class', 'y axis')\n      .attr('clip-path', 'url(#clip_visidb4eec110-2a26-4710-9fa8-f678a2a1b52c_chart1_vaxis)');\n    vis.append('clipPath').attr('id', 'clip_visidb4eec110-2a26-4710-9fa8-f678a2a1b52c_chart1_vaxis').append('polyline')\n      .attr('points', '-1000,-10000, 10000,-10000, 10000,' + (geom.inner_rawHeight+1) + ', -1,' + (geom.inner_rawHeight+1) + ', -1,' + (geom.inner_rawHeight+5) + ', -1000,' + (geom.inner_rawHeight+5) );\n    axes.select('g.axis.y').append('text').attr('class', 'title').text('True Positive Rate').style('text-anchor', 'middle')\n      .attr('x',-geom.inner_rawHeight/2)\n      .attr('y', 4-geom.inner_left).attr('dy', '0.7em').attr('transform', 'rotate(270)');\n\n    var axis_bottom = d3.axisBottom(scale_x).ticks(Math.min(10, Math.round(geom.inner_width / 33.0)));\n    var axis_left = d3.axisLeft(scale_y).ticks(Math.min(10, Math.round(geom.inner_width / 20)));\n\n    function buildAxes(time) {\n      var axis_x = axes.select('g.axis.x');\n      BrunelD3.transition(axis_x, time).call(axis_bottom.scale(scale_x));\n      var axis_y = axes.select('g.axis.y');\n      BrunelD3.transition(axis_y, time).call(axis_left.scale(scale_y));\n      BrunelD3.makeGrid(gridGroup, scale_x, geom.inner_height, true );\n      BrunelD3.makeGrid(gridGroup, scale_y, geom.inner_width, false );\n    }\n    zoom.on('zoom', function(t, time) {\n        t = t ||BrunelD3.restrictZoom(d3.event.transform, geom, this);\n        scale_x = t.rescaleX(base_scales[0]);\n        scale_y = t.rescaleY(base_scales[1]);\n        zoomNode.__zoom = t;\n        interior.attr('class', 'interior ' + BrunelD3.zoomLabel(t.k));;\n        build(time || -1);\n    });\n\n    // Define element #1 ///////////////////////////////////////////////////////////////////////////\n\n    elements[0] = function() {\n      var original, processed,           // data sets passed in and then transformed\n        element, data,                   // Brunel element information and brunel data\n        selection, merged;               // D3 selection and merged selection\n      var elementGroup = interior.append('g').attr('class', 'element1'),\n        main = elementGroup.append('g').attr('class', 'main'),\n        labels = BrunelD3.undoTransform(elementGroup.append('g').attr('class', 'labels').attr('aria-hidden', 'true'), elementGroup);\n\n      function makeData() {\n        original = datasets[0];\n        if (filterRows) original = original.retainRows(filterRows);\n        processed = pre(original, 0)\n          .sortRows('FPR:ascending');\n        processed = post(processed, 0);\n        var f0 = processed.field('FPR'),\n          f1 = processed.field('TPR'),\n          f2 = processed.field('#row'),\n          f3 = processed.field('#selection');\n        var keyFunc = function(d) { return 'ALL' };\n        data = {\n          FPR:          function(d) { return f0.value(d.row) },\n          TPR:          function(d) { return f1.value(d.row) },\n          $row:         function(d) { return f2.value(d.row) },\n          $selection:   function(d) { return f3.value(d.row) },\n          FPR_f:        function(d) { return f0.valueFormatted(d.row) },\n          TPR_f:        function(d) { return f1.valueFormatted(d.row) },\n          $row_f:       function(d) { return f2.valueFormatted(d.row) },\n          $selection_f: function(d) { return f3.valueFormatted(d.row) },\n          _split:       function(d) { return 'ALL' },\n          _key:         keyFunc,\n          _rows:        BrunelD3.makeRowsWithKeys(keyFunc, processed.rowCount())\n        };\n      }\n\n      // Build element from data ///////////////////////////////////////////////////////////////////\n\n      function build(transitionMillis) {\n        element = elements[0];\n        var w = geom.default_point_size;\n        var x = function(d) { return scale_x(data.FPR(d))};\n        var h = Math.abs( scale_y(scale_y.domain()[0] + 0.09813084112149528) - scale_y.range()[0] );\n        var y = function(d) { return scale_y(data.TPR(d))};\n        // Define paths\n        var path = d3.line().x(x).y(y);\n        var splits = BrunelD3.makePathSplits(data, path, x);\n\n        // Define selection entry operations\n        function initialState(selection) {\n          selection\n            .attr('class', 'element line')\n        }\n\n        // Define selection update operations on merged data\n        function updateState(selection) {\n          selection\n            .attr('d', function(d) { return d.path });\n        }\n\n        // Define labeling for the selection\n        function label(selection, transitionMillis) {\n\n          var tooltipLabeling = {\n            method: 'path', location: ['center', 'center'], inside: true, align: 'middle', pad: 0, dy: 0.3,\n            fit: true, granularity: 0,\n            path: path,\n            content: function(d) {\n              return d.row == null ? null : '<span class=\"title\">FPR: </span>'\n\t\t\t+ '<span class=\"field\">' + data.FPR_f(d) + '</span>'\n\t\t\t+ '<br/>'\n\t\t\t+ '<span class=\"title\">TPR: </span>'\n\t\t\t+ '<span class=\"field\">' + data.TPR_f(d) + '</span>'\n            }\n          };\n          BrunelD3.addTooltip(selection, tooltipLabeling, geom);\n        }\n        // Create selections, set the initial state and transition updates\n        selection = main.selectAll('.element').data(splits, function(d) { return d.key });\n        var added = selection.enter().append('path');\n        merged = selection.merge(added);\n        initialState(added);\n        selection.filter(hasData).classed('selected', isSelected(data)).filter(isSelected(data)).raise();\n        updateState(BrunelD3.transition(merged, transitionMillis));\n        label(merged, transitionMillis);\n\n        BrunelD3.transition(selection.exit(), transitionMillis/3)\n          .style('opacity', 0.5).each( function() {\n            this.remove(); if (this.__label__) this.__label__.remove()\n        });\n      }\n\n      return {\n        data:           function() { return processed },\n        original:       function() { return original },\n        internal:       function() { return data },\n        selection:      function() { return merged },\n        makeData:       makeData,\n        build:          build,\n        chart:          function() { return charts[0] },\n        group:          function() { return elementGroup },\n        fields: {\n          x:            ['FPR'],\n          y:            ['TPR']\n        }\n      };\n    }();\n\n    function build(time, noData) {\n      var first = elements[0].data() == null;\n      if (first) time = 0; // No transition for first call\n      buildAxes(time);\n      if ((first || time > -1) && !noData)elements[0].makeData();\n      elements[0].build(time);\n    }\n\n    // Expose the following components of the chart\n    return {\n      elements : elements,\n      interior : interior,\n      scales: {x:scale_x, y:scale_y},\n      zoom: function(params, time) {\n          if (params) zoom.on('zoom').call(zoomNode, params, time);\n          return d3.zoomTransform(zoomNode);\n      },\n      build : build\n    };\n    }();\n\n  function setData(rowData, i) { datasets[i||0] = BrunelD3.makeData(rowData) }\n  function updateAll(time) { charts.forEach(function(x) {x.build(time || 0)}) }\n  function buildAll() {\n    for (var i=0;i<arguments.length;i++) setData(arguments[i], i);\n    updateAll(transitionTime);\n  }\n\n  return {\n    dataPreProcess:     function(f) { if (f) pre = f; return pre },\n    dataPostProcess:    function(f) { if (f) post = f; return post },\n    data:               function(d,i) { if (d) setData(d,i); return datasets[i||0] },\n    visId:              visId,\n    build:              buildAll,\n    rebuild:            updateAll,\n    charts:             charts\n  }\n}\n\n// Data Tables /////////////////////////////////////////////////////////////////////////////////////\n\nvar table1 = {\n   names: ['FPR', 'TPR'], \n   options: ['numeric', 'numeric'], \n   rows: [[0, 0], [0.00284495, 0.90186916], [1, 1], [1, 1]]\n};\n\n// Call Code to Build the system ///////////////////////////////////////////////////////////////////\n\nvar v = new BrunelVis('visidb4eec110-2a26-4710-9fa8-f678a2a1b52c');\nv.build(table1);\n\n            \"\"\n        });\n        });\n        </script>"}, "execution_count": 11, "metadata": {}}], "metadata": {"trusted": true}}, {"source": "", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "mokshaspark2.0.2 - Scala", "name": "mokshaspark2.0.2_scala", "language": "scala"}, "language_info": {"file_extension": ".scala", "version": "2.11.8", "name": "scala"}}}