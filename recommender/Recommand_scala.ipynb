{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from http://9.30.146.148/elasticsearch-spark-20_2.11-5.3.0.jar\n",
      "Finished download of elasticsearch-spark-20_2.11-5.3.0.jar\n"
     ]
    }
   ],
   "source": [
    "%Addjar --magic http://9.30.146.148/elasticsearch-spark-20_2.11-5.3.0.jar -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.elasticsearch.spark._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkConf\n",
    "val conf =new SparkConf().setAppName(\"Recommand\").setMaster(\"spark://xmo1.fyre.ibm.com:7077\")\n",
    "    conf.set(\"es.index.auto.create\",\"true\")\n",
    "    conf.set(\"es.nodes\",\"9.30.101.216\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------------+------+\n",
      "|movieId|rating|           timestamp|userId|\n",
      "+-------+------+--------------------+------+\n",
      "|    253|   3.0|1970-01-10 11:23:...|    50|\n",
      "|    282|   3.0|1970-01-10 11:23:...|    50|\n",
      "|    368|   4.0|1970-01-10 11:23:...|    50|\n",
      "|    480|   4.0|1970-01-10 11:23:...|    50|\n",
      "|    587|   3.0|1970-01-10 11:23:...|    50|\n",
      "+-------+------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings_df.write.format(\"es\").save(\"demo0/ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val numbers = Map(\"one\" -> 1, \"two\" -> 2, \"three\" -> 3)\n",
    "val airports = Map(\"arrival\" -> \"Otopeni\", \"SFO\" -> \"San Fran\")\n",
    "sc.makeRDD(Seq(numbers, airports)).saveToEs(\"spark/docs\")\n",
    "val RDD = sc.esRDD(\"demo/users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.elasticsearch.spark._\n",
    "import org.apache.spark.SparkContext    \n",
    "import org.apache.spark.SparkContext._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- @model: struct (nullable = true)\n",
      " |    |-- factor: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n",
      "+------+-----------------+\n",
      "|userId|             name|\n",
      "+------+-----------------+\n",
      "|   547|     Betty George|\n",
      "|   370|   Patrick Browne|\n",
      "|   587|        John Leal|\n",
      "|   637|Christopher Weeks|\n",
      "|   380|   Margaret Moore|\n",
      "+------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val user_df = spark.read.format(\"es\").load(\"demo/users\")\n",
    "user_df.printSchema()\n",
    "user_df.select(\"userId\", \"name\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- @model: struct (nullable = true)\n",
      " |    |-- factor: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- originalTitle: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- release_date: timestamp (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+--------------------+--------------------+----------+\n",
      "|movieId|               title|              genres|        release_date|popularity|\n",
      "+-------+--------------------+--------------------+--------------------+----------+\n",
      "|   4712|      The Wild Child|             [Drama]|1970-02-26 00:00:...|  0.139692|\n",
      "|   8236|While the City Sl...|  [Drama, Film-Noir]|1956-05-30 00:00:...|  0.439121|\n",
      "|   7335|Pickup on South S...|         [Film-Noir]|1953-05-29 00:00:...|  0.122243|\n",
      "|  48711|   Facing the Giants|     [Action, Drama]|2006-09-29 00:00:...|  0.601298|\n",
      "|  41585|       Kiss of Death|[Crime, Drama, Fi...|1947-08-27 00:00:...|  0.601486|\n",
      "+-------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val movie_df = spark.read.format(\"es\").option(\"es.read.field.as.array.include\", \"genres\").load(\"demo/movies\")\n",
    "movie_df.printSchema()\n",
    "movie_df.select(\"movieId\", \"title\", \"genres\", \"release_date\", \"popularity\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n",
      "+-------+------+--------------------+------+\n",
      "|movieId|rating|           timestamp|userId|\n",
      "+-------+------+--------------------+------+\n",
      "|    296|   4.0|1970-01-10 11:23:...|    50|\n",
      "|    377|   3.0|1970-01-10 11:23:...|    50|\n",
      "|    454|   3.0|1970-01-10 11:23:...|    50|\n",
      "|    786|   3.0|1970-01-10 11:23:...|    50|\n",
      "|   1636|   1.0|1970-01-11 22:45:...|    51|\n",
      "+-------+------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val ratings_df = spark.read.format(\"es\").load(\"demo/ratings\")\n",
    "ratings_df.printSchema()\n",
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.recommendation.ALS\n",
    "import org.apache.spark.sql.functions.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val als = new ALS().setUserCol(\"userId\").setItemCol(\"movieId\").setRatingCol(\"rating\").setRegParam(0.1).setRank(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|            features|\n",
      "+---+--------------------+\n",
      "| 10|[0.2868985, 0.517...|\n",
      "| 20|[-0.02282229, -0....|\n",
      "| 30|[-0.038180783, 0....|\n",
      "| 40|[0.38619977, 0.06...|\n",
      "| 50|[0.053539716, -0....|\n",
      "+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+--------------------+\n",
      "| id|            features|\n",
      "+---+--------------------+\n",
      "| 10|[0.52807945, 0.09...|\n",
      "| 20|[0.45714593, 0.14...|\n",
      "| 30|[0.388741, 0.8019...|\n",
      "| 40|[0.6537328, 0.176...|\n",
      "| 50|[0.54700166, 0.34...|\n",
      "+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val converted_ratings = ratings_df.select(col(\"userId\").cast(\"int\"), col(\"movieId\").cast(\"int\"),col(\"rating\"))\n",
    "val model = als.fit(converted_ratings)\n",
    "model.userFactors.show(5)\n",
    "model.itemFactors.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:41: error: value features is not a member of org.apache.spark.sql.Row\n",
       "       val test_vec = model.userFactors.select(\"features\").first().features\n",
       "                                                                   ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// test out the vector conversion function\n",
    "val test_vec = model.userFactors.select(\"features\").first().features\n",
    "print test_vec\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:2: error: ':' expected but ')' found.\n",
       "def convert_vector(x):\n",
       "                    ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.functions.{ udf, lit }\n",
    "\n",
    "def convert_vector(x):\n",
    "    '''Convert a list or numpy array to delimited token filter format'''\n",
    "    return \" \".join([\"%s|%s\" % (i, v) for i, v in enumerate(x)])\n",
    "def reverse_convert(s):\n",
    "    '''Convert a delimited token filter format string back to list format'''\n",
    "    return  [float(f.split(\"|\")[1]) for f in s.split(\" \")]\n",
    "def vector_to_struct(x, version):\n",
    "    '''Convert a vector to a SparkSQL Struct with string-format vector and version fields'''\n",
    "    return (convert_vector(x), version)\n",
    "vector_struct = udf(vector_to_struct, \\\n",
    "                    StructType([StructField(\"factor\", StringType(), True), \\\n",
    "                                StructField(\"version\", StringType(), True)]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Spark2.0 - Scala",
   "language": "scala",
   "name": "spark2.0_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
