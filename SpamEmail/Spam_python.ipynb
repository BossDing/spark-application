{"nbformat_minor": 0, "nbformat": 4, "cells": [{"source": "\n# Email Spam Classification Pipeline\n## 1. Read labeled email data\n\n1 = ham 0 = spam\n", "cell_type": "markdown", "metadata": {}}, {"source": "\nfrom pyspark.sql import SparkSession\n\n# @hidden_cell\n# This function is used to setup the access of Spark to your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share your notebook.\ndef set_hadoop_config_with_credentials_64e9c4bd3e4148978db0a312dfcc0a93(name):\n    \"\"\"This function sets the Hadoop configuration so it is possible to\n    access data from Bluemix Object Storage using Spark\"\"\"\n\n    prefix = 'fs.swift.service.' + name\n    hconf = sc._jsc.hadoopConfiguration()\n    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n    hconf.set(prefix + '.tenant', '419cd8dece644c82af5a615b62af38e1')\n    hconf.set(prefix + '.username', 'babc87c7f7b5482c83c36c78831298be')\n    hconf.set(prefix + '.password', 'qilA8zqp0/F?C,!!')\n    hconf.setInt(prefix + '.http.port', 8080)\n    hconf.set(prefix + '.region', 'dallas')\n    hconf.setBoolean(prefix + '.public', False)\n\n# you can choose any name\nname = 'keystone'\nset_hadoop_config_with_credentials_64e9c4bd3e4148978db0a312dfcc0a93(name)\n\nspark = SparkSession.builder.getOrCreate()\n\n# Please read the documentation of PySpark to learn more about the possibilities to load data files.\n# PySpark documentation: https://spark.apache.org/docs/2.0.1/api/python/pyspark.sql.html#pyspark.sql.SparkSession\n# The SparkSession object is already initalized for you.\n# The following variable contains the path to your file on your Object Storage.\npath_1 = \"swift://SpamDetection.\" + name + \"/part-r-00000-939c4239-aeb8-44a6-9c29-90d7ab74de65.snappy.parquet\"\n\n# Please read the documentation of PySpark to learn more about the possibilities to load data files.\n# PySpark documentation: https://spark.apache.org/docs/2.0.1/api/python/pyspark.sql.html#pyspark.sql.SparkSession\n# The SparkSession object is already initalized for you.\n# The following variable contains the path to your file on your Object Storage.\npath_2 = \"swift://SpamDetection.\" + name + \"/part-r-00001-939c4239-aeb8-44a6-9c29-90d7ab74de65.snappy.parquet\"", "execution_count": 2, "cell_type": "code", "metadata": {"collapsed": true}, "outputs": []}, {"source": "from pyspark.sql.functions import udf, col\nfrom pyspark.sql.types import *\ndata=spark.read.parquet(\"swift://SpamDetection.keystone/\")\ndata.cache()\ndata.printSchema()\nspamData = data.select(col(\"email_id\"), col(\"text\"), col(\"label\").cast(DoubleType()))\nspamData.cache()\nspamData.printSchema()\nspamData.show(5)\nspamData.count()", "execution_count": 19, "cell_type": "code", "metadata": {"collapsed": false}, "outputs": [{"output_type": "stream", "text": "root\n |-- email_id: long (nullable = true)\n |-- text: string (nullable = true)\n |-- label: integer (nullable = true)\n\nroot\n |-- email_id: long (nullable = true)\n |-- text: string (nullable = true)\n |-- label: double (nullable = true)\n\n+--------+--------------------+-----+\n|email_id|                text|label|\n+--------+--------------------+-----+\n|       1|One of a kind Mon...|  0.0|\n|      10|Re: What to choos...|  1.0|\n|     100|Strictly Private....|  0.0|\n|    1000|Re: Flash is open...|  1.0|\n|    1001|Re: Alsa/Redhat 8...|  1.0|\n+--------+--------------------+-----+\nonly showing top 5 rows\n\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 19, "data": {"text/plain": "2500"}, "metadata": {}}]}, {"source": "# Split data into training (80%) and test (20%)\ntrainDF, testDF = spamData.randomSplit([0.8, 0.2])\n#print \"The number of training data is \",trainDF.count()\n#print \"The number of test data is \",spamData.count()", "execution_count": 20, "cell_type": "code", "metadata": {"collapsed": false}, "outputs": []}, {"source": "print\"Training data: %d\" % spamData.count()", "execution_count": 4, "cell_type": "code", "metadata": {"collapsed": false}, "outputs": [{"output_type": "stream", "text": "Training data: 2500\n", "name": "stdout"}]}, {"source": "\n## 2. Create a Spark ML pipeline consisting of:\n\n    Tokenizer - extract tokens from raw text\n    Count vectorizer - convert tokens to term-frequency vectors\n    IDF - normalize term-frequency vectors using TF-IDF\n    Logistic Regression for binary classification\n\n", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.feature import RegexTokenizer,CountVectorizer,IDF\nfrom pyspark.ml.tuning import CrossValidator,ParamGridBuilder\nfrom pyspark.ml import Pipeline", "execution_count": 5, "cell_type": "code", "metadata": {"collapsed": true}, "outputs": []}, {"source": "tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"[^a-zA-Z_0-9]+\")\ncv = CountVectorizer(inputCol=\"words\", outputCol=\"tf\")\nidf = IDF(inputCol=\"tf\", outputCol=\"features\")\nlr = LogisticRegression(maxIter=150)\npipeline = Pipeline(stages=[tokenizer, cv, idf, lr])", "execution_count": 6, "cell_type": "code", "metadata": {"collapsed": true}, "outputs": []}, {"source": "## 3. Use K-fold Cross Validation for Model Selection for Pipeline", "cell_type": "markdown", "metadata": {}}, {"source": "auc_eval = BinaryClassificationEvaluator()\ngrid = ParamGridBuilder() \\\n    .addGrid(lr.regParam, [1e-3, 1e-2]) \\\n    .addGrid(lr.elasticNetParam, [0.25, 0.0]) \\\n    .addGrid(cv.vocabSize, [10000, 50000]) \\\n    .addGrid(idf.minDocFreq, [0, 3]) \\\n    .build()\ncross_val = CrossValidator(estimator=pipeline, evaluator=auc_eval, estimatorParamMaps=grid, numFolds=3)", "execution_count": 7, "cell_type": "code", "metadata": {"collapsed": true}, "outputs": []}, {"source": "pipeline_model = cross_val.fit(trainDF)\ntestResult=pipeline_model.transform(testDF)", "execution_count": 12, "cell_type": "code", "metadata": {"collapsed": true}, "outputs": []}, {"source": "scores = zip(grid, pipeline_model.avgMetrics)\nscores.sort(key=lambda x: x[1], reverse=True)\nprint \"Cross-validation scores:\"\nfor s in scores:\n    p = s[0]\n    print \"regParam: %s; elasticNet: %s, vocabSize: %s, minDocFreq: %s - ROC score: %s\" % \\\n        (p[lr.regParam], p[lr.elasticNetParam], p[cv.vocabSize], p[idf.minDocFreq], s[1])", "execution_count": 13, "cell_type": "code", "metadata": {"collapsed": false}, "outputs": [{"output_type": "stream", "text": "Cross-validation scores:\nregParam: 0.01; elasticNet: 0.0, vocabSize: 50000, minDocFreq: 3 - ROC score: 0.992134839512\nregParam: 0.01; elasticNet: 0.25, vocabSize: 50000, minDocFreq: 0 - ROC score: 0.992075087481\nregParam: 0.01; elasticNet: 0.0, vocabSize: 10000, minDocFreq: 3 - ROC score: 0.99196725177\nregParam: 0.01; elasticNet: 0.0, vocabSize: 10000, minDocFreq: 0 - ROC score: 0.991959774715\nregParam: 0.01; elasticNet: 0.25, vocabSize: 50000, minDocFreq: 3 - ROC score: 0.991774806979\nregParam: 0.01; elasticNet: 0.25, vocabSize: 10000, minDocFreq: 3 - ROC score: 0.991656833128\nregParam: 0.01; elasticNet: 0.25, vocabSize: 10000, minDocFreq: 0 - ROC score: 0.99156355421\nregParam: 0.001; elasticNet: 0.25, vocabSize: 50000, minDocFreq: 0 - ROC score: 0.991513830707\nregParam: 0.001; elasticNet: 0.0, vocabSize: 50000, minDocFreq: 3 - ROC score: 0.991034904831\nregParam: 0.001; elasticNet: 0.0, vocabSize: 10000, minDocFreq: 3 - ROC score: 0.990587910962\nregParam: 0.001; elasticNet: 0.0, vocabSize: 10000, minDocFreq: 0 - ROC score: 0.990423936359\nregParam: 0.01; elasticNet: 0.0, vocabSize: 50000, minDocFreq: 0 - ROC score: 0.990247722987\nregParam: 0.001; elasticNet: 0.25, vocabSize: 50000, minDocFreq: 3 - ROC score: 0.989820863258\nregParam: 0.001; elasticNet: 0.0, vocabSize: 50000, minDocFreq: 0 - ROC score: 0.9890861071\nregParam: 0.001; elasticNet: 0.25, vocabSize: 10000, minDocFreq: 3 - ROC score: 0.988745658314\nregParam: 0.001; elasticNet: 0.25, vocabSize: 10000, minDocFreq: 0 - ROC score: 0.988369834168\n", "name": "stdout"}]}, {"source": "## 4. Evaluate the trained model and draw the ROC curve", "cell_type": "markdown", "metadata": {}}, {"source": "import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve\ntestDF=testResult.select(\"prediction\",\"label\").toPandas()\na=np.array(testDF.label)\nb=np.array(testDF.prediction)\nfpr, tpr, thresholds = roc_curve(a, b, pos_label=1)\ndata={'FPR':fpr,'TPR':tpr}\nrocPD=pd.DataFrame(data)", "execution_count": 14, "cell_type": "code", "metadata": {"collapsed": true}, "outputs": []}, {"source": "import brunel\n%brunel data('rocPD') x(FPR) y(TPR) line tooltip(#all) axes(x:'False Positive Rate':grid, y:'True Positive Rate':grid)", "execution_count": 15, "cell_type": "code", "metadata": {"collapsed": false}, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<!--\n  ~ Copyright (c) 2015 IBM Corporation and others.\n  ~\n  ~ Licensed under the Apache License, Version 2.0 (the \"License\");\n  ~ You may not use this file except in compliance with the License.\n  ~ You may obtain a copy of the License at\n  ~\n  ~     http://www.apache.org/licenses/LICENSE-2.0\n  ~\n  ~ Unless required by applicable law or agreed to in writing, software\n  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  ~ See the License for the specific language governing permissions and\n  ~ limitations under the License.\n  -->\n\n\n<link rel=\"stylesheet\" type=\"text/css\" href=\"/data/jupyter2/c0a5987a-d373-482a-8eaa-ecfae906ffcb/nbextensions/brunel_ext/Brunel.css\">\n<link rel=\"stylesheet\" type=\"text/css\" href=\"/data/jupyter2/c0a5987a-d373-482a-8eaa-ecfae906ffcb/nbextensions/brunel_ext/sumoselect/sumoselect.css\">\n\n<style>\n    \n</style>\n\n<svg id=\"visid3f8c0b3c-0c66-11e7-b952-002590fb6db4\" width=\"500\" height=\"400\"></svg>"}, "metadata": {}}, {"output_type": "execute_result", "execution_count": 15, "data": {"application/javascript": "/*\n * Copyright (c) 2015 IBM Corporation and others.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * You may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nrequire.config({\n    waitSeconds: 60,\n    paths: {\n        'd3': '//cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min',\n        'BrunelD3': '/data/jupyter2/c0a5987a-d373-482a-8eaa-ecfae906ffcb/nbextensions/brunel_ext/BrunelD3',\n        'BrunelData': '/data/jupyter2/c0a5987a-d373-482a-8eaa-ecfae906ffcb/nbextensions/brunel_ext/BrunelData',\n        'BrunelEventHandlers': '/data/jupyter2/c0a5987a-d373-482a-8eaa-ecfae906ffcb/nbextensions/brunel_ext/BrunelEventHandlers'\n    },\n    shim: {\n        'BrunelD3': {\n            exports: 'BrunelD3'\n        },\n        'BrunelData': {\n            exports: 'BrunelData'\n        },\n        'BrunelEventHandlers': {\n            exports: 'BrunelEventHandlers'\n        },\n    }\n\n});\n\nrequire([\"d3\"], function(d3) {\nrequire([\"BrunelD3\", \"BrunelData\", \"BrunelEventHandlers\"], function(BrunelD3, BrunelData, BrunelEventHandlers) {\n    function  BrunelVis(visId) {\n  \"use strict\"; // Strict Mode\n  var datasets = [],                               // Array of datasets for the original data\n      pre = function(d, i) { return d },           // Default pre-process does nothing\n      post = function(d, i) { return d },          // Default post-process does nothing\n      transitionTime = 200,                        // Transition time for animations\n      charts = [],                                 // The charts in the system\n      vis = d3.select('#' + visId).attr('class', 'brunel');  // the SVG container\n\n  // Define chart #1 in the visualization //////////////////////////////////////////////////////////\n\n  charts[0] = function(parentNode, filterRows) {\n    var geom = BrunelD3.geometry(parentNode || vis.node(), 0, 0, 1, 1, 5, 45, 36, 12),\n      elements = [];                               // Array of elements in this chart\n\n    // Define groups for the chart parts ///////////////////////////////////////////////////////////\n\n    var chart = vis.append('g').attr('class', 'chart1')\n      .attr('transform','translate(' + geom.chart_left + ',' + geom.chart_top + ')');\n    chart.append('rect').attr('class', 'background').attr('width', geom.chart_right-geom.chart_left).attr('height', geom.chart_bottom-geom.chart_top);\n    var interior = chart.append('g').attr('class', 'interior')\n      .attr('transform','translate(' + geom.inner_left + ',' + geom.inner_top + ')')\n      .attr('clip-path', 'url(#clip_visid3f8c0b3c-0c66-11e7-b952-002590fb6db4_1)');\n    interior.append('rect').attr('class', 'inner').attr('width', geom.inner_width).attr('height', geom.inner_height);\n    var overlay = interior.append('g').attr('class', 'element')\n      .attr('class', 'overlay').style('cursor','move').style('fill','none').style('pointer-events','all');\n    var zoom = d3.behavior.zoom().on('zoom', function() {build(-1)} );\n    overlay.append('rect').attr('class', 'overlay')\n      .attr('width', geom.inner_width)\n      .attr('height', geom.inner_height)\n      .call(zoom);\n    var axes = chart.append('g').attr('class', 'axis')\n      .attr('transform','translate(' + geom.inner_left + ',' + geom.inner_top + ')');\n    vis.append('clipPath').attr('id', 'clip_visid3f8c0b3c-0c66-11e7-b952-002590fb6db4_1').append('rect')\n      .attr('x', -1).attr('y', -1)\n      .attr('width', geom.inner_width+2).attr('height', geom.inner_height+2);\n\n    // Scales //////////////////////////////////////////////////////////////////////////////////////\n\n    var scale_x = d3.scale.linear()\n      .domain([0, 1])\n      .range([0, geom.inner_width]);\n    var scale_inner = d3.scale.linear().domain([0,1])\n      .range([-0.5, 0.5]);\n    var scale_y = d3.scale.linear()\n      .domain([0, 1])\n      .range([geom.inner_height,0]);\n    zoom.x(scale_x).y(scale_y);\n\n    // Axes ////////////////////////////////////////////////////////////////////////////////////////\n\n    axes.append('g').attr('class', 'x axis')\n      .attr('transform','translate(0,' + geom.inner_height + ')');\n    axes.select('g.axis.x').append('text').attr('class', 'title')\n      .attr('text-anchor', 'middle')\n      .attr('x', geom.inner_width/2)\n      .attr('y', geom.inner_bottom - 6)\n      .text('False Positive Rate');\n    axes.append('g').attr('class', 'y axis')\n      .attr('transform','translate(geom.chart_left, 0)');\n    axes.select('g.axis.y').append('text').attr('class', 'title')\n      .attr('text-anchor', 'middle')\n      .attr('x', -geom.inner_height/2)\n      .attr('y', 6-geom.inner_left).attr('dy', '0.7em').attr('transform', 'rotate(270)')\n      .text('True Positive Rate');\n\n    var axis_bottom = d3.svg.axis()\n      .scale(scale_x).innerTickSize(3).outerTickSize(0)\n      .ticks(Math.min(10, Math.round(geom.inner_width / 28.5)));\n    var axis_left = d3.svg.axis().orient('left')\n      .scale(scale_y).innerTickSize(3).outerTickSize(0);\n\n    function buildAxes() {\n      axes.select('g.axis.x').call(axis_bottom);\n      axes.select('g.axis.y').call(axis_left);\n    }\n\n    // Define element #1 ///////////////////////////////////////////////////////////////////////////\n\n    elements[0] = function() {\n      var original, processed,           // data sets passed in and then transformed\n        element, data,                   // Brunel element information and brunel data\n        selection;                       // D3 selection\n      var elementGroup = interior.append('g').attr('class', 'element1'),\n        main = elementGroup.append('g').attr('class', 'main'),\n        labels = BrunelD3.undoTransform(elementGroup.append('g').attr('class', 'labels'), elementGroup);\n\n      function makeData() {\n        original = datasets[0];\n        if (filterRows) original = original.retainRows(filterRows);\n        processed = pre(original, 0)\n          .sortRows('FPR:ascending');\n        processed = post(processed, 0);\n        var f0 = processed.field('FPR'),\n          f1 = processed.field('TPR'),\n          f2 = processed.field('#row');\n        var keyFunc = function(d) { return 'ALL' };\n        data = {\n          FPR:          function(d) { return f0.value(d.row) },\n          TPR:          function(d) { return f1.value(d.row) },\n          $row:         function(d) { return f2.value(d.row) },\n          FPR_f:        function(d) { return f0.valueFormatted(d.row) },\n          TPR_f:        function(d) { return f1.valueFormatted(d.row) },\n          $row_f:       function(d) { return f2.valueFormatted(d.row) },\n          _split:       function(d) { return 'ALL' },\n          _key:         keyFunc,\n          _rows:        BrunelD3.makeRowsWithKeys(keyFunc, processed.rowCount())\n        };\n      }\n\n      // Build element from data ///////////////////////////////////////////////////////////////////\n\n      function build(transitionMillis) {\n        element = elements[0];\n        var x = function(d) { return scale_x(data.FPR(d))};\n        var w = function(d) { return Math.abs( scale_x(0.118055555556) - scale_x(0) )};\n        var y = function(d) { return scale_y(data.TPR(d))};\n        var h = geom.default_point_size;\n        var path = d3.svg.line().x(x).y(y);\n        var splits = BrunelD3.makePathSplits(data, path, x);\n        selection = main.selectAll('*').data(splits, function(d) { return d.key});\n        selection.enter().append('path').attr('class',  'element line');\n\n        BrunelD3.trans(selection,transitionMillis)\n          .attr('d', function(d) { return d.path });\n\n        var tooltipLabeling = {\n          method: 'path', \n          fit: true,\n          path: path,\n          content: function(d) {\n            return d.row == null ? null : '<span class=\"title\">FPR: </span>'\n\t\t\t+ '<span class=\"field\">' + data.FPR_f(d) + '</span>'\n\t\t\t+ '<br/>'\n\t\t\t+ '<span class=\"title\">TPR: </span>'\n\t\t\t+ '<span class=\"field\">' + data.TPR_f(d) + '</span>'\n          }\n        };\n        BrunelD3.addTooltip(selection, tooltipLabeling, geom);\n\n        BrunelD3.trans(selection.exit(),transitionMillis/3)\n          .style('opacity', 0.5).each( function() {this.remove(); if (this.__label__) this.__label__.remove()});\n      }\n\n      return {\n        data:           function() { return processed },\n        internal:       function() { return data },\n        selection:      function() { return selection },\n        makeData:       makeData,\n        build:          build,\n        fields: {\n          x:            ['FPR'],\n          y:            ['TPR']\n        }\n      };\n    }();\n\n    function build(time) {\n      var first = elements[0].data() == null;\n      if (first) time = 0; // No transition for first call\n      buildAxes(); \n      if (first || time>0) elements[0].makeData();\n      elements[0].build(time);\n    }\n\n    // Expose the following components of the chart\n    return { build : build, elements : elements };\n    }();\n\n  function setData(rowData, i) { datasets[i||0] = BrunelD3.makeData(rowData) }\n  function updateAll(time) { charts.forEach(function(x) {x.build(time || 20)}) }\n  function buildAll() {\n    for (var i=0;i<arguments.length;i++) setData(arguments[i], i);\n    updateAll(transitionTime);\n  }\n\n  return {\n    dataPreProcess:     function(f) { if (f) pre = f; return pre },\n    dataPostProcess:    function(f) { if (f) post = f; return post },\n    data:               function(d,i) { if (d) setData(d,i); return datasets[i||0] },\n    visId:              visId,\n    build:              buildAll,\n    rebuild:            updateAll,\n    charts:             charts\n  }\n}\n\n// Data Tables /////////////////////////////////////////////////////////////////////////////////////\n\nvar table1 = {\n   names: ['FPR', 'TPR'], \n   options: ['numeric', 'numeric'], \n   rows: [[0, 0], [0.11805556, 0.98816568], [1, 1]]\n};\n\n// Call Code to Build the system ///////////////////////////////////////////////////////////////////\n\nvar v = new BrunelVis('visid3f8c0b3c-0c66-11e7-b952-002590fb6db4');\nv.build(table1);\n\n    \n});\n});", "text/plain": "<IPython.core.display.Javascript object>"}, "metadata": {}}]}, {"source": "\n## 5. Predict data with the trained model", "cell_type": "markdown", "metadata": {}}, {"source": "# example pipeline output\nspamData.show(5)\npipeline_model.transform(spamData).select(\"text\", \"words\", \"features\", \"label\", \"prediction\").show(5)", "execution_count": 16, "cell_type": "code", "metadata": {"collapsed": false}, "outputs": [{"output_type": "stream", "text": "+--------+--------------------+-----+\n|email_id|                text|label|\n+--------+--------------------+-----+\n|       1|One of a kind Mon...|  0.0|\n|      10|Re: What to choos...|  1.0|\n|     100|Strictly Private....|  0.0|\n|    1000|Re: Flash is open...|  1.0|\n|    1001|Re: Alsa/Redhat 8...|  1.0|\n+--------+--------------------+-----+\nonly showing top 5 rows\n\n+--------------------+--------------------+--------------------+-----+----------+\n|                text|               words|            features|label|prediction|\n+--------------------+--------------------+--------------------+-----+----------+\n|One of a kind Mon...|[one, of, a, kind...|(50000,[0,1,2,3,5...|  0.0|       0.0|\n|Re: What to choos...|[re, what, to, ch...|(50000,[0,1,2,3,5...|  1.0|       1.0|\n|Strictly Private....|[strictly, privat...|(50000,[0,1,2,3,5...|  0.0|       0.0|\n|Re: Flash is open...|[re, flash, is, o...|(50000,[0,1,2,3,5...|  1.0|       1.0|\n|Re: Alsa/Redhat 8...|[re, alsa, redhat...|(50000,[0,1,2,3,5...|  1.0|       1.0|\n+--------------------+--------------------+--------------------+-----+----------+\nonly showing top 5 rows\n\n", "name": "stdout"}]}], "metadata": {"kernelspec": {"name": "python2-spark20", "display_name": "Python 2 with Spark 2.0", "language": "python"}, "language_info": {"nbconvert_exporter": "python", "mimetype": "text/x-python", "version": "2.7.11", "pygments_lexer": "ipython2", "name": "python", "file_extension": ".py", "codemirror_mode": {"version": 2, "name": "ipython"}}}}